{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f983911b",
   "metadata": {},
   "source": [
    "In this example we show how the model hub can be used to get the contribution of features to reaching conversion. With the model hub, you can estimate the contribution, as well as evaluate the model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f492f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelhub import ModelHub\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6c189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model hub\n",
    "modelhub = ModelHub(time_aggregation='YYYY-MM-DD')\n",
    "# get the Bach DataFrame with Objectiv data\n",
    "df = modelhub.get_objectiv_dataframe(start_date='2022-02-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3768bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define which events to use as conversion events\n",
    "modelhub.add_conversion_event(location_stack=df.location_stack.json[{'id': 'objectiv-on-github', \n",
    "                                                                     '_type': 'LinkContext'}:].fillna(\n",
    "                                             df.location_stack.json[{'id': 'github', '_type': 'LinkContext'}:]),\n",
    "                              event_type='PressEvent',\n",
    "                              name='github_press')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236d8e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['root'] = df.location_stack.ls.get_from_context_with_type_series(type='RootLocationContext', key='id')\n",
    "df['nice_name'] = df.location_stack.ls.nice_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83e7206",
   "metadata": {},
   "source": [
    "We want to obtain the impact of pressing in individual sections (root location) on our website. We assume a true causal relation between the number of clicks per root location and conversion. Make sure to think of this assumption when using this model on your own data. Therefore we estimate conversion by the number of presses in each root location on our site per user using a logistic regression model. The coefficients of this regression can be interpreted as the contribution to conversion (direction and magnitude). \n",
    "\n",
    "The feature importance model returns a trained model, but also the data sets that is used for training the model based on the parameters. \n",
    "\n",
    "This let's you adjust the data set further or use the model as is.\n",
    "\n",
    "The model has methods for the accuracy assesment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e0660d",
   "metadata": {},
   "source": [
    "#### todo \n",
    "\n",
    "model should be a class that allows for rerunning the data on a cleaned data set. currently just a dict with results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08485d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo, do return the model but not fitted\n",
    "# X_temp, y_temp, model = modelhub.agg.feature_importance_new(\n",
    "#     data=df[df.event_type=='PressEvent'],\n",
    "#     name='github_press',\n",
    "#     feature_column='root'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425b967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp, y_temp = modelhub.agg.create_feature_usage_data_set(\n",
    "    data=df[df.event_type=='PressEvent'],\n",
    "    name='github_press',\n",
    "    feature_column='root'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eb9035",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c88e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7580bbc6",
   "metadata": {},
   "source": [
    "In our example, we will go into detailed assessment of the model's accuracy, so we won't jumpt to the model results, but instead first look at our data set and prepare a proper data set for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4add891",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_temp = X_temp.copy()\n",
    "data_set_temp['is_converted'] = y_temp\n",
    "# todo sum axis = 1? now gets all user ids\n",
    "data_set_temp['total_press'] = X_temp.stack().to_frame().reset_index().groupby('user_id').__stacked.sum().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892c7955",
   "metadata": {},
   "source": [
    "### Cleaning the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a364490",
   "metadata": {},
   "source": [
    "First the data set has to be prepared. The data set and the relation between predictors and the predicted classes have to fulfill several assumptions, such as there are sample size, linearity between features and log odds and no influential outliers. We look at our data to try to get the best possible data set for the model`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e505d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_temp.describe().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d41954",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_temp.is_converted.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032873b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_set_temp.is_converted.value_counts()/data_set_temp.is_converted.count()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1a07fc",
   "metadata": {},
   "source": [
    "We see most variables have a mean of less than zero. We can also look at the distributions of the variables. We split the histograms for each variable by conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9949439",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# figure, axis = plt.subplots(len(X_temp.data_columns), 2,figsize=(15,30))\n",
    "\n",
    "# for idx, name in enumerate(X_temp.data_columns):\n",
    "#     data_set_temp[data_set_temp.is_converted==True][['about']].plot.hist(bins=20,title='Converted',ax=axis[idx][0])\n",
    "#     data_set_temp[data_set_temp.is_converted==False][['about']].plot.hist(bins=20,title='Not converted',ax=axis[idx][1])\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2053a4a5",
   "metadata": {},
   "source": [
    "To make this problem less, we first drop two variables that have (almost) no distribution at all: privacy and join slack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488eead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_temp = data_set_temp.drop(columns=['privacy','join-slack'])\n",
    "columns_remaining = [x for x in data_set_temp.data_columns if x in X_temp.data_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25efdb73",
   "metadata": {},
   "source": [
    "Also, to unskew the data, we drop all users that have visited only one page, as we believe that such cases don't have any explanatory power to the target (it means reaching the goal after one click). \n",
    "\n",
    "Those might, for instance, be users that wanted to go to our github, and this was the quickest way to get there with the results Google provided them. In that case, the intent of the user (something of which we can never be sure), was going to the github page. The features did not convince them. \n",
    "\n",
    "By filtering like this, it is more likely that the used features on our website did, or did not convince a user to check out our product on github. This is exactly what we are after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637fb4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_temp = data_set_temp[data_set_temp.total_press>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d560011",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_temp.describe().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218150c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# figure, axis = plt.subplots(len(X_temp.data_columns), 2,figsize=(15,30))\n",
    "\n",
    "# for idx, name in enumerate(X_temp.data_columns):\n",
    "#     data_set_temp[data_set_temp.is_converted==True][['about']].plot.hist(bins=20,title='Converted',ax=axis[idx][0])\n",
    "#     data_set_temp[data_set_temp.is_converted==False][['about']].plot.hist(bins=20,title='Not converted',ax=axis[idx][1])\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f18d276",
   "metadata": {},
   "source": [
    "Although our feature usage is still skewed, with many users using a feature 0 times, it is better than before. The data set is also smaller, but (slgihtly) more balanced. This can be seen from the (in most cases) higher mean and std as well as the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e631dacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_temp.is_converted.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd356f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_set_temp.is_converted.value_counts()/data_set_temp.is_converted.count()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97ea37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data_set_temp[columns_remaining+['is_converted']]\n",
    "X = data_set[columns_remaining]\n",
    "y = data_set.is_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5936f0",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c68f2ca",
   "metadata": {},
   "source": [
    "The model of choice is a logistic regression. This model gives a probablity of converting and also lets us interpret the feature coefficients, which is key to our goal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4381230f",
   "metadata": {},
   "source": [
    "#### Error metric\n",
    "\n",
    "We choose the error metric. Not overall f1 score, becasue we have an imbalanced dataset. So we look at predicting conversions in particular, while keeping in mind that overall accuracy shouldnt drop too much.\n",
    "\n",
    "One way is to balance data set, but we don't cause we want to use all data.\n",
    "\n",
    "The most important measure of model goodness is AUC. The reason is that we are not so much interested in the actual predicted label, as we are interested in the coefficients of the model. The AUC can then give a good indication of performance compared to a baseline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66080f6",
   "metadata": {},
   "source": [
    "The 'feature_importance_proto' model splits the data in five folds and runs the model five times. The results is based on the average of the coeficients of the five runs. The AUC for each model is averaged and interpreted as model goodness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c5d42c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = modelhub.aggregate.feature_importance_proto(X, y, print_report = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7858c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['auc_mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4191d818",
   "metadata": {},
   "source": [
    "The average of the AUC on the five test sets indicates an ok performance. Therefore the coefficients can be interpreted as giving some explanation to predicting conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49947877",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d3059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['coef']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e37fe0a",
   "metadata": {},
   "source": [
    "The average feature coeficient, for most features is, quite stable and has the same sign for all runs, tested solely on unseen data for model training. The lower the std, the more certain we are of the actual value of the feature importance. Do note that 3/4 of every training set contains the same data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
