{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f983911b",
   "metadata": {},
   "source": [
    "In this example we show how the model hub can be used to get the contribution of features to reaching conversion. With the model hub, you can estimate the contribution, as well as evaluate the model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f492f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelhub import ModelHub\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6c189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model hub\n",
    "modelhub = ModelHub(time_aggregation='YYYY-MM-DD')\n",
    "# get the Bach DataFrame with Objectiv data\n",
    "df = modelhub.get_objectiv_dataframe(start_date='2022-02-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3768bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define which events to use as conversion events\n",
    "modelhub.add_conversion_event(location_stack=df.location_stack.json[{'id': 'objectiv-on-github', \n",
    "                                                                     '_type': 'LinkContext'}:].fillna(\n",
    "                                             df.location_stack.json[{'id': 'github', '_type': 'LinkContext'}:]),\n",
    "                              event_type='PressEvent',\n",
    "                              name='github_press')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236d8e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['root'] = df.location_stack.ls.get_from_context_with_type_series(type='RootLocationContext', key='id')\n",
    "df['nice_name'] = df.location_stack.ls.nice_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08485d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = modelhub.agg.create_feature_usage_data_set(\n",
    "    data=df[df.event_type=='PressEvent'],\n",
    "    name='github_press',\n",
    "    feature_column='root'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f946c8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp = X.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4c806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_temp = y.to_pandas().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4add891",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_temp = X_temp.copy()\n",
    "data_set_temp['is_converted'] = y_temp\n",
    "data_set_temp['total_press'] = X_temp.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d926395f",
   "metadata": {},
   "source": [
    "We want to obtain the impact of pressing in individual sections (root location) on our website. We do this by estimating conversion by the number of presses in each root location on our site per user using a logistic regression model. The coefficients of this regression can be interpreted as the contribution to conversion (direction and magnitude). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892c7955",
   "metadata": {},
   "source": [
    "### cleaning the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a364490",
   "metadata": {},
   "source": [
    "First the data set has to be prepared. The data set and the relation between predictors and the predicted classes have to fulfill several assumptions, such as there are sample size, linearity between features and log odds and no influential outliers. We look at our data to try to get the best possible data set for the model`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e505d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_temp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d41954",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_temp.is_converted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032873b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_temp.is_converted.value_counts()/len(data_set_temp.is_converted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1a07fc",
   "metadata": {},
   "source": [
    "We see most variables have a mean of less than zero. We can also look at the distributions of the variables. We split the histograms for each variable by conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fd8386",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(len(X_temp.columns), 2,figsize=(15,30))\n",
    "\n",
    "for idx, name in enumerate(X_temp.columns):\n",
    "    data_set_temp[data_set_temp.is_converted==1].plot(column=name,by='is_converted',kind='hist',ax=axis[idx][0],bins=20)\n",
    "    data_set_temp[data_set_temp.is_converted==0].plot(column=name,by='is_converted',kind='hist',ax=axis[idx][1],bins=20)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2053a4a5",
   "metadata": {},
   "source": [
    "To make this problem less, we first drop two variables that have (almost) no distribution at all: privacy and join slack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488eead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_temp.drop(columns=['privacy','join-slack'], inplace=True)\n",
    "columns_remaining = [x for x in data_set_temp.columns if x in X_temp.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25efdb73",
   "metadata": {},
   "source": [
    "Also, to unskew the data, we drop all users that have visited only one page, as we believe that such cases don't have any explanatory power to the target (it means reaching the goal after one click). \n",
    "\n",
    "Those might, for instance, be users that wanted to go to our github, and this was the quickest way to get there with the results Google provided them. In that case, the intent of the user (something of which we can never be sure), was going to the github page. The features did not convince them. \n",
    "\n",
    "By filtering like this, it is more likely that the used features on our website did, or did not convince a user to check out our product on github. This is exactly what we are after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637fb4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_temp = data_set_temp[data_set_temp.total_press>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d560011",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_temp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218150c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(len(columns_remaining), 2,figsize=(15,30))\n",
    "\n",
    "for idx, name in enumerate(data_set_temp[columns_remaining]):\n",
    "    data_set_temp[data_set_temp.is_converted==1].plot(column=name,by='is_converted',kind='hist',ax=axis[idx][0],bins=20)\n",
    "    data_set_temp[data_set_temp.is_converted==0].plot(column=name,by='is_converted',kind='hist',ax=axis[idx][1],bins=20)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f18d276",
   "metadata": {},
   "source": [
    "Although our feature usage is still skewed, with many users using a feature 0 times, it is better than before. The data set is also smaller, but (slgihtly) more balanced. This can be seen from the (in most cases) higher mean and std as well as the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e631dacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_temp.is_converted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd356f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_temp.is_converted.value_counts()/len(data_set_temp.is_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97ea37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data_set_temp[columns_remaining+['is_converted']]\n",
    "X = data_set[columns_remaining]\n",
    "y = data_set.is_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5936f0",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4381230f",
   "metadata": {},
   "source": [
    "we choose error metric. not accuracy (what is that f1?) becasue we have an imbalanced dataset. so we look at predicting conversions in particular, while keeping in mind that overall accuracy shouldnt drop too much.\n",
    "\n",
    "one way is to balance data set, but we don't cause we want to use all data.\n",
    "\n",
    "The model of choice is a logistic regression. this model gives a probablity of converting and also lets us interpret the feature coefficients, which is key to our goal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acce71e8",
   "metadata": {},
   "source": [
    "For our assessment of the model fit we won't choose the overall 'accuracy'. This tends to get high with skewed data set (that we have). \n",
    "\n",
    "The most important measure of model goodness is AUC. The reason is that we are not so much interested in the actual predicted label, as we are interested in the coefficients of the model. The AUC can then give a good indication of performance compared to a baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66080f6",
   "metadata": {},
   "source": [
    "The 'feature_importance_proto' model splits the data in five folds and runs the model five times. The results is based on the average of the coeficients of the five runs. The AUC for each model is averaged and interpreted as model goodness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c5d42c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = modelhub.aggregate.feature_importance_proto(X,y, print_report = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7858c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['auc_mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4191d818",
   "metadata": {},
   "source": [
    "The avera of the AUC on the five test sets indicates a decent performance. Therefore the coefficients can be interpreted as giving some explanation to predicting conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49947877",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d3059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['coef']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e37fe0a",
   "metadata": {},
   "source": [
    "The average feature coeficient, for most features is, quite stable and has the same sign for all runs, tested solely on unseen data for model training. The lower the std, the more certain we are of the actual value of the feature importance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
